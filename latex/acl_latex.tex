% 基本规约请参考腾讯共享文档-资料汇总-ChatDev课题组论文写作会.paf
% 段落和句子逻辑梳理，约时间讨论确定内容，之后再正式起笔
% 核心信息量尽量一次性写到位（ABC原则），避免反复大修

\pdfoutput=1
\documentclass[11pt]{article}
\usepackage[review]{acl}
\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{amsmath}
\usepackage{amssymb}

\newcommand{\ie}{\textit{i.e., }}
\newcommand{\eg}{\textit{e.g., }}
\newcommand{\etal}{\textit{et al. }}
\newcommand{\etc}{\textit{etc. }}
\newcommand{\wrt}{\textit{w.r.t. }}
\newcommand{\cf}{\textit{cf. }}
\newcommand{\aka}{\textit{a.k.a. }}

\title{}

\author{}

\begin{document}
\maketitle

\clearpage
\section{Interactive Co-Learning}
Recent work has found that it is difficult to solve complex problems directly using large models at once. Examples include arithmetic reasoning, writing software, creative writing.

A promising approach is to replace human intervention with an autonomous communicative agent capable of steering by using autonomous interaction of multi-agents the conversation toward task completion.

The core reason for the success of this paradigm is that the multi-agent interaction will divide the task solution into a chain of subtasks. Along the nodes of the chain, interation of agents is further activated to achieve sequential resolution of subtasks, solution modification, and cross-examination.

Recent advances, \eg ChatDev and Camel, adopt the kernel of chain-style schema to divide the software development process into several distinct phases (such as coding, reviewing, testing). At each phase, agents with different roles participate in the analysis and discussion in order to produce a new code version of that phase.
Each step in the chain involves two types of roles: instructor and assiatant.
In each chat, an instructor initiates instructions, guiding the dialogue towards task completion, while the assistant follows the instructions, provides suitable solutions, and engages in discussions.
The instructor continuously provides instructions to the assistant for task-solving, after which they collaboratively communicate by chatting with each other in an instruction-following fashion until they reach a consensus and determine that the subtask has been successfully accomplished.
Whenever a subtask is accomplished by interactive discussion, a node will produce a solution, which can be in the form of code.


\subsection{Co-Working}
This module presents an autonomous interaction paradigm, where collaboration occurs between two distinct language agents: an instructor and an assistant. The main goal of this co-working phase is to develop a detailed set of "historical trajectories" through their cooperative task solving, which is a record of the subtask chain capturing the evolution of the task through each state and the consequent interactions.

Formally, define \( \mathcal{T} \) as the set of tasks to be executed. For each task \( t \in \mathcal{T} \), the instructor and the assistant engage in a series of interactions specifically oriented towards task resolution. Within this process, the instructor provides a set of instructions \( \mathcal{I} = \{i_1, i_2, ..., i_n\} \) for each task \( t \). In response, the assistant generates a sequence of answers \( \mathcal{A} = \{a_0\} \cup \{a_1, a_2, ..., a_n\} \), corresponding to these instructions, where \( a_0 \) denotes the initial state, assumed to be empty.

The interaction for each task \( t \) is depicted as a sequence of pairs in \( \mathcal{M} = \{(i_1, a_1), (i_2, a_2), ..., (i_k, a_n)\} \). Each pair consists of an instruction from the instructor and the corresponding response from the assistant. The solution or intermediate resolution to each task is derived from \( \mathcal{A} \). For instance, in the ChatDev framework—a tool powered by agent interaction for software development—the entire evolution of code development can be extracted from the sequence of responses.\footnote{For simplicity, we assume that each response of the assistant directly corresponds to the solution (e.g., a piece of source code). However, responses often include additional ideas expressed in natural language, which can be parsed using regular expressions.}
With this definition, the process of solving each task \( t \) can be modeled as a directed chain \( \mathcal{G} = (\mathcal{N}, \mathcal{E}) \):
\[
\left\{
\begin{array}{ll}
\mathcal{N} = \{ a_j | a_j \in \mathcal{A} \} \\
\mathcal{E} = \{ (a_{j-1}, i_j, a_j) | a_{j-1}, a_j \in \mathcal{A}, i_j \in \mathcal{I} \}
\end{array}
\right.
\]
where \( \mathcal{N} \) represents the set of nodes corresponding to the states of the task, and \( \mathcal{E} \) represents the set of edges, each denoting an interaction between the instructor and the assistant. Each node \( a_j \) aligns with the \( j \)-th state of the task \( t \). The edges \( (a_{j-1}, i_j, a_j) \) signify the transition from state \( a_{j-1} \) to state \( a_j \), driven by instruction \( i_j \).
Similar to the hidden Markov models, the directed chain \( \mathcal{G} \) clearly captures the solution state transition process of the two types of agents during task completion.


\subsection{Co-Memorizing}
The co-memorizing Module is strategically designed to foster mutual growth in two distinct types of language agents. This module aims to enhance their capabilities by imparting knowledge beyond their current mastery. The agents’ existing capabilities, internalized within large-scale neurons, are represented as directly connected nodes in the task processing chain. However, this conventional approach of knowledge transfer through neighboring nodes is often inadequate for substantial capability enhancement.

At the heart of the co-memorizing mechanism is the innovative concept of utilizing non-directly connected edges within the task processing chain as "shortcuts". These shortcuts provide a means to infuse agents with advanced knowledge, thus empowering them to effectively handle unseen tasks. The module specifically concentrates on establishing "pseudo connections" between non-adjacent nodes. By internalizing these head-to-tail connections as "growth nutrients", agents are theoretically equipped to solve specific tasks more efficiently and in fewer steps.

Nonetheless, our observations reveal that autonomous steps by agents in software development do not always progress towards the desired outcomes. State deviations are a common occurrence, leading the development process to diverge unexpectedly from the intended solution. Such deviations manifest in various forms, such as a transition from functional base software to a state of compilation failure, version backtracking in the software’s source code rendering previous steps obsolete, or the generation of irrelevant code fragments when the assistant encounters instructions beyond its programming capability.

Given these insights, it becomes evident that not every non-directly connected edge serves as an effective shortcut for knowledge transfer. Hence, a crucial component of the co-memorizing module is the judicious selection of these shortcuts, tailored to enhance the mutual growth and efficacy of the agents.

To address the challenge of state deviations, we introduce a novel empirical screening mechanism for identifying high-quality shortcuts. This mechanism conceptualizes the task execution chain as a graph structure, potentially inclusive of self-loops. Each node within this graph is evaluated based on feedback from the external environment, such as software compilation signals. The process involves exploring the information gain provided by non-directly connected edges through augmented paths, thereby enabling the filtration and selection of superior shortcuts that enrich the agents' experiential knowledge.

In addressing the backtracking issue prevalent in agents' code iteration processes, we introduce a method to explicitly expose backtracked source code states within the graph structure. This involves coupling the same source code states by their content. We achieve this by mapping the nodes of the task execution chain \( \mathcal{G} = (\mathcal{N}, \mathcal{E}) \) to a directed graph \( \hat{\mathcal{G}} = (\hat{\mathcal{N}}, \hat{\mathcal{E}}) \) as follows:
\[
\left\{
\begin{array}{ll}
\hat{\mathcal{N}} = \{ \phi(a_j) | a_j \in \mathcal{N} \} \\
\hat{\mathcal{E}} = \{ (\phi(a_{j-1}), i_j, \phi(a_j)) | (a_{j-1}, i_j, a_j) \in \mathcal{E} \}
\end{array}
\right.
\]

To estimate the relevance of each node \( \hat{a}_j \) in \( \hat{\mathcal{N}} \) to the terminal node \( \hat{a}_{|\hat{\mathcal{N}}|} \), we employ a self-supervised pairwise estimation:
\[
f(\hat{a}_j) = sim(\hat{a}_j, task) \times sim(\hat{a}_j, \hat{a}_{|\hat{\mathcal{N}}|}) \times [\![\hat{a}_j]\!]
\]
where \( sim(\cdot) \) is a function computing similarity, assessing the alignment between a node (i.e., code) and the task, and between the node and the terminal node; \( [\![\cdot]\!] \) indicates whether the node has successfully passed compilation.

We then identify potential shortcuts in the task \( t \) as pairs of nodes that are not directly connected but reachable, with their information gain surpassing a threshold \( \epsilon \):
\[
\begin{aligned}
\hat{\mathcal{S}} = \{ (\hat{a}_i, \hat{a}_i \leadsto \hat{a}_j, \hat{a}_j) | \hat{a}_i, \hat{a}_j \in \hat{\mathcal{N}^*} \wedge (\hat{a}_i, \cdot, \hat{a}_j) \notin \mathcal{E} \\ 
\wedge [\![ \hat{a}_i \Rightarrow \hat{a}_j ]\!] \wedge f(a_j) - f(a_i) \geq \epsilon \}
\end{aligned}
\]
where \( \hat{\mathcal{N}^*} \) represents nodes along the shortest path in \( \hat{\mathcal{N}} \); \( [\![ \hat{a}_i \Rightarrow \hat{a}_j ]\!] \) indicates reachability from \( \hat{a}_i \) to \( \hat{a}_j \); and \( \hat{a}_i \leadsto \hat{a}_j \) symbolizes a pseudo instruction facilitating the state transition, realized through a self-instruct mechanism.

Leveraging this heuristic shortcut extraction, the instructor stores code-to-text pairs \( \hat{\mathcal{S}}_\mathcal{I} = \{(\hat{a}_i, \hat{a}_i \leadsto \hat{a}_j)\} \) in its memory card, enabling it to provide refined instructions to the assistant based on the current solution. Conversely, the assistant stores text-to-code pairs \( \hat{\mathcal{S}}_\mathcal{A} = \{(\hat{a}_i \leadsto \hat{a}_j, \hat{a}_j)\} \) in its memory card, allowing it to offer improved solutions upon receiving instructions. This collaborative memorization mechanism, or co-memorizing, fosters co-evolution between the instructor and the assistant, bringing an opportunity for the realization of reciprocal reasoning.


\subsection{Co-Reasoning}
The co-reasoning module is designed to leverage the accumulated experiences of both the instructor and the assistant. When encountering an unseen task, they utilize their respective memories to retrieve and exchange optimal results, thereby enhancing their problem-solving approach for the task at hand.

In practice, this process begins when the instructor, equipped with a code-to-text memory, encounters a current state \( \hat{a}_j \). The instructor then retrieves the most suitable instruction from its memory. This instruction is not merely a instruction but also serves as an in-context example for his/her reasoning. The instruction that emerges from this example-augmented in-context reasoning result is then provided to the assistant.
Subsequently, the assistant, possessing a text-to-code memory, retrieves the optimal code in response to the received instruction. This optimal code piece acts as a basis for the assistant's in-context reasoning, culminating in the generation of a new state \( \hat{a}_{j+1}^* \). The process can be formalized as:
\[
\begin{aligned}
i_{j+1}^* &= \mathbb{I}(\hat{a}_j, \mathbb{R}(\hat{\mathcal{S}}_\mathcal{I}, i_{j+1})) \\
\hat{a}_{j+1}^* &= \mathbb{A}(\hat{a}_j, \mathbb{R}(\hat{\mathcal{S}}_\mathcal{A}, i_{j+1}^*)) \\
\end{aligned}
\]
where \( \mathbb{I} \) and \( \mathbb{A} \) denote the reasoning processes of the instructor and assistant, respectively; \( \mathbb{R} \) represents the retrieval function that taps into the shared memory \( \hat{\mathcal{S}} \) to find the optimal examples for code-to-text (\( \hat{\mathcal{S}}_\mathcal{I} \)) and text-to-code (\( \hat{\mathcal{S}}_\mathcal{A} \)) transformations.

Through this iterative reasoning and memory retrieval cycle, the instructor and assistant synergistically enhance their problem-solving capabilities. The co-reasoning module thus plays a pivotal role in facilitating inference based on the mutual memory of the two language agents, propelling them towards more effective task resolution.

\end{document}
